{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Arnnoon/my_LM/blob/main/wizard_of_oz.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ5koPc1ZVsD",
        "outputId": "98da1fdb-5d69-4b41-e987-50cea6af18c9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-16 06:32:55--  https://github.com/Arnnoon/my_LM/blob/main/wizard_of_oz.txt\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 276954 (270K) [text/plain]\n",
            "Saving to: ‘wizard_of_oz.txt’\n",
            "\n",
            "wizard_of_oz.txt    100%[===================>] 270.46K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-12-16 06:32:55 (9.08 MB/s) - ‘wizard_of_oz.txt’ saved [276954/276954]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ8iLMWDXNA_",
        "outputId": "15632cc1-541a-48cc-ce93-b5f40564d8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import mmap\n",
        "import random\n",
        "import pickle\n",
        "import argparse\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# batch_size = args.batch_size # to use the batch_size cmd arg -> python file_name.py -batch_size 32\n",
        "batch_size = 32\n",
        "block_size = 128\n",
        "max_iters = 3000\n",
        "learning_rate = 3e-4\n",
        "eval_iters = 50\n",
        "n_embd = 384\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "chars = sorted(set(text))\n",
        "print(chars)\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL0c7lLCXjA_",
        "outputId": "df2217ab-9c32-4586-b591-f01ca2818d03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '!', '\"', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '·', '\\ufeff']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
        "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])"
      ],
      "metadata": {
        "id": "htTKteuWYZG9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "fdxKteFBYauu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "t3dQXrTfYfNW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "# [1, 0, 0]\n",
        "# [1, 0.6, 0]\n",
        "# [1, 0.6, 0.4]\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.sa(x)\n",
        "        x = self.ln1(x + y)\n",
        "        y = self.ffwd(x)\n",
        "        x = self.ln2(x + y)\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        # index is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            index_cond = index[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self.forward(index_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
        "        return index\n",
        "\n",
        "model = GPTLanguageModel(vocab_size)\n",
        "# print('loading model parameters...')\n",
        "# with open('model-01.pkl', 'rb') as f:\n",
        "#     model = pickle.load(f)\n",
        "# print('loaded successfully!')\n",
        "m = model.to(device)"
      ],
      "metadata": {
        "id": "K_T8l3GkYz0p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_iters == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model.forward(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())\n",
        "\n",
        "with open('me_llm_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "print('Model saved successfully.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qkqn0mq5Y1YC",
        "outputId": "d3f6787a-be85-4093-fe20-d90675b22ac6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, train loss: 4.526, val loss: 4.564\n",
            "step: 50, train loss: 2.382, val loss: 3.602\n",
            "step: 100, train loss: 2.287, val loss: 3.639\n",
            "step: 150, train loss: 2.189, val loss: 3.388\n",
            "step: 200, train loss: 2.081, val loss: 3.586\n",
            "step: 250, train loss: 1.971, val loss: 3.479\n",
            "step: 300, train loss: 1.895, val loss: 3.649\n",
            "step: 350, train loss: 1.808, val loss: 3.755\n",
            "step: 400, train loss: 1.739, val loss: 3.734\n",
            "step: 450, train loss: 1.679, val loss: 3.516\n",
            "step: 500, train loss: 1.626, val loss: 3.434\n",
            "step: 550, train loss: 1.564, val loss: 3.229\n",
            "step: 600, train loss: 1.530, val loss: 3.323\n",
            "step: 650, train loss: 1.487, val loss: 3.113\n",
            "step: 700, train loss: 1.466, val loss: 3.168\n",
            "step: 750, train loss: 1.434, val loss: 2.987\n",
            "step: 800, train loss: 1.410, val loss: 3.114\n",
            "step: 850, train loss: 1.390, val loss: 3.210\n",
            "step: 900, train loss: 1.368, val loss: 3.093\n",
            "step: 950, train loss: 1.345, val loss: 3.245\n",
            "step: 1000, train loss: 1.332, val loss: 3.043\n",
            "step: 1050, train loss: 1.314, val loss: 2.891\n",
            "step: 1100, train loss: 1.296, val loss: 2.986\n",
            "step: 1150, train loss: 1.282, val loss: 2.823\n",
            "step: 1200, train loss: 1.260, val loss: 2.581\n",
            "step: 1250, train loss: 1.237, val loss: 2.926\n",
            "step: 1300, train loss: 1.238, val loss: 2.880\n",
            "step: 1350, train loss: 1.230, val loss: 2.666\n",
            "step: 1400, train loss: 1.214, val loss: 2.753\n",
            "step: 1450, train loss: 1.197, val loss: 2.803\n",
            "step: 1500, train loss: 1.183, val loss: 2.947\n",
            "step: 1550, train loss: 1.171, val loss: 2.591\n",
            "step: 1600, train loss: 1.164, val loss: 2.645\n",
            "step: 1650, train loss: 1.145, val loss: 2.814\n",
            "step: 1700, train loss: 1.144, val loss: 2.739\n",
            "step: 1750, train loss: 1.129, val loss: 2.581\n",
            "step: 1800, train loss: 1.126, val loss: 2.809\n",
            "step: 1850, train loss: 1.124, val loss: 2.318\n",
            "step: 1900, train loss: 1.105, val loss: 2.377\n",
            "step: 1950, train loss: 1.095, val loss: 2.562\n",
            "step: 2000, train loss: 1.091, val loss: 2.623\n",
            "step: 2050, train loss: 1.084, val loss: 2.598\n",
            "step: 2100, train loss: 1.078, val loss: 2.851\n",
            "step: 2150, train loss: 1.071, val loss: 2.805\n",
            "step: 2200, train loss: 1.067, val loss: 2.649\n",
            "step: 2250, train loss: 1.064, val loss: 3.087\n",
            "step: 2300, train loss: 1.040, val loss: 2.825\n",
            "step: 2350, train loss: 1.043, val loss: 2.815\n",
            "step: 2400, train loss: 1.030, val loss: 2.724\n",
            "step: 2450, train loss: 1.031, val loss: 2.716\n",
            "step: 2500, train loss: 1.016, val loss: 3.097\n",
            "step: 2550, train loss: 1.014, val loss: 2.979\n",
            "step: 2600, train loss: 1.012, val loss: 3.165\n",
            "step: 2650, train loss: 0.996, val loss: 2.931\n",
            "step: 2700, train loss: 0.993, val loss: 2.696\n",
            "step: 2750, train loss: 0.988, val loss: 2.615\n",
            "step: 2800, train loss: 0.975, val loss: 2.831\n",
            "step: 2850, train loss: 0.968, val loss: 2.844\n",
            "step: 2900, train loss: 0.972, val loss: 2.829\n",
            "step: 2950, train loss: 0.960, val loss: 2.837\n",
            "1.0461912155151367\n",
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Hello! Can you see me?'\n",
        "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=100)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwDuE-seY8qk",
        "outputId": "679d59a6-a67f-460a-d8f5-840c394f9a7e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! Can you see me? Believing while.\\r\";\"\\\"At all, my Ling I tell.\\\"\\r\",\"\\r\",\"The mountain a great This beside much sai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    prompt = input(\"Prompt:\\n\")\n",
        "    context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
        "    generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=150)[0].tolist())\n",
        "    print(f'Completion:\\n{generated_chars}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V33ikcUhH4xY",
        "outputId": "fa6a3a3e-2b7f-4607-efc8-813334862fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "Dorothy's companions\n",
            "Completion:\n",
            "Dorothy's companions it with their eyeleven;\\r\",\"\\\"What are content put not do, oft come.\\\"\\r\",\"\\r\",\"That had been to soones cattages, on her perfor had tailty.\\\"\\r\",\"\\r\"\n",
            "\n",
            "Prompt:\n",
            "Wizard of Oz help Dorothy\n",
            "Completion:\n",
            "Wizard of Oz help Dorothy, \\\"why had heel have\\r\",\"to round, nawhole being her in her nockly and road with like hoses\\r\",\"hard and thumble vart until bridling. Buts her and\\r\"\n",
            "\n",
            "Prompt:\n",
            "Dorothy's perception of home\n",
            "Completion:\n",
            "Dorothy's perception of homed. There!\\\"\\r\",\"\\r\",\"The little, who I'm on. You tried it means as good with much can\\r\",\"his cotting babbiting, just I want away to neight.\\\"\\r\",\"\\r\"\n",
            "\n",
            "Prompt:\n",
            "night\n",
            "Completion:\n",
            "night, bearly; \\\"but it no the\\r\",\"fine.\\\"\\r\",\"\\r\",\"\\\"I'll falst it foun that so counto the Gargoyles. After,\\\" she shring that said, \\\"we much\\r\",\"returne\n",
            "\n"
          ]
        }
      ]
    }
  ]
}